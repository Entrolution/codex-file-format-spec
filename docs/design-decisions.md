# Design Decisions

This document records key design decisions made during the Codex format specification development.

## DD-001: ZIP Container Format

**Decision**: Use ZIP archive as the container format.

**Alternatives Considered**:
1. Custom binary format
2. Single JSON file
3. Tar archive
4. SQLite database

**Rationale**:
- ZIP is universally supported across platforms
- Enables random access to individual files
- Familiar tooling for debugging and inspection
- Built-in compression support
- EPUB, DOCX, ODF all use ZIP successfully

**Consequences**:
- Slight overhead compared to custom format
- Must handle ZIP-specific edge cases (path traversal, etc.)

---

## DD-002: JSON as Primary Data Format

**Decision**: Use JSON for all structured data (manifest, content, metadata).

**Alternatives Considered**:
1. XML
2. YAML
3. Protocol Buffers
4. MessagePack/CBOR

**Rationale**:
- JSON is human-readable for debugging
- Universal parser support across languages
- Easy to version control (text diffs work)
- JSON Schema provides validation
- JCS (RFC 8785) enables deterministic hashing

**Consequences**:
- Larger file sizes than binary formats
- Some types require conventions (dates as ISO 8601 strings)
- Deep nesting can be verbose

---

## DD-003: Semantic-First Content Model

**Decision**: Store content as semantic blocks, not visual instructions.

**Alternatives Considered**:
1. PDF-style drawing operators
2. HTML-like tag soup
3. Markdown with extensions

**Rationale**:
- Separates meaning from presentation
- Enables multiple output formats from single source
- Machine extraction works reliably
- Accessibility is natural, not bolted on
- Aligns with modern editor architectures (ProseMirror, Slate)

**Consequences**:
- Requires presentation layer for visual rendering
- Some legacy documents harder to convert
- More complex than flat text

---

## DD-004: Content-Addressable Document Identity

**Decision**: Document ID is the hash of its canonical content.

**Alternatives Considered**:
1. UUID assigned at creation
2. Sequential version numbers
3. Timestamp-based IDs
4. No formal ID (filename only)

**Rationale**:
- Hash = identity enables integrity verification
- No central authority needed for ID assignment
- Identical content produces identical IDs (deduplication)
- Enables distributed storage and caching
- Git uses this model successfully

**Consequences**:
- Draft documents need special handling (pending ID)
- Hash must be recomputed on content change
- Canonical form must be precisely defined

---

## DD-005: Explicit Document State Machine

**Decision**: Documents have explicit states (draft, review, frozen, published).

**Alternatives Considered**:
1. Implicit state from signatures (PDF model)
2. No state concept
3. Continuous versioning only

**Rationale**:
- PDF's implicit model has proven confusing and exploitable
- Clear states communicate author intent
- Enables proper enforcement (frozen = no edits)
- Supports workflow integration

**Consequences**:
- State transitions must be validated
- Implementations must respect state semantics
- Adds complexity over simple version numbers

---

## DD-006: SHA-256 as Default Hash Algorithm

**Decision**: Use SHA-256 as the default hashing algorithm, with algorithm agility.

**Alternatives Considered**:
1. SHA-1 (legacy compatibility)
2. SHA-3 only (newest)
3. BLAKE3 (fastest)
4. Multiple required algorithms

**Rationale**:
- SHA-256 has excellent security margin
- Universally implemented
- Matches common certificate standards
- Algorithm agility allows future migration
- SHA-3 and BLAKE3 as options for those who want them

**Consequences**:
- Must specify algorithm in hash string
- Implementations must support migration path

---

## DD-007: ES256 as Required Signature Algorithm

**Decision**: ECDSA with P-256 (ES256) is the minimum required signature algorithm.

**Alternatives Considered**:
1. RSA only (legacy)
2. Ed25519 only (modern)
3. Multiple required algorithms

**Rationale**:
- ES256 balances security, performance, and compatibility
- Required by WebAuthn, widely deployed
- Ed25519 recommended but not required (support still growing)
- RSA optional for legacy integration

**Consequences**:
- Must support at least one ECDSA implementation
- Post-quantum algorithms as optional extension

---

## DD-008: Optional Presentation Layers

**Decision**: Presentation layers are optional; default rendering from semantics.

**Alternatives Considered**:
1. Required presentation layer
2. No presentation concept (pure semantic)
3. Inline styling only

**Rationale**:
- Simple documents don't need complex layouts
- Semantic content can be rendered with defaults
- Presentation is an optimization, not requirement
- Enables progressive enhancement

**Consequences**:
- Implementations must provide default styles
- Rendering may vary slightly across implementations
- Complex layouts require explicit presentation

---

## DD-009: Modular Extension Architecture

**Decision**: Core specification is minimal; features added via extensions.

**Alternatives Considered**:
1. Monolithic specification
2. Profiles (subsets)
3. Completely open extension model

**Rationale**:
- Keeps core simple and implementable
- Extensions can evolve independently
- Implementations can support what they need
- Prevents specification bloat

**Consequences**:
- Must define extension registration mechanism
- Required vs optional extensions need clear semantics
- Interoperability requires common extension support

---

## DD-010: No Scripting in Core

**Decision**: Core specification does not support executable content.

**Alternatives Considered**:
1. JavaScript support (like PDF)
2. Sandboxed scripting
3. Declarative interactivity only

**Rationale**:
- Security risks outweigh benefits
- PDF JavaScript is a major attack vector
- Interactivity can be achieved through forms extension
- Static documents are easier to preserve

**Consequences**:
- Some PDF features not directly portable
- Interactive features require extension or viewer support
- Clearer security model

---

## DD-011: Dublin Core as Required Metadata

**Decision**: Dublin Core metadata is required for all documents.

**Alternatives Considered**:
1. Custom metadata schema
2. XMP (Adobe)
3. No required metadata
4. Schema.org only

**Rationale**:
- Dublin Core is an established standard (ISO 15836)
- Minimal required set (title, creator)
- Extensible for domain-specific needs
- Compatible with library and archive systems

**Consequences**:
- All documents have basic discoverability
- Additional schemas as extensions
- Slight overhead for very simple documents

---

## DD-012: Annotation Layer Separate from Content

**Decision**: Annotations on frozen documents are stored separately, not affecting content hash.

**Alternatives Considered**:
1. Annotations as content (changes hash)
2. No annotations on frozen documents
3. Annotation versioning separate from content

**Rationale**:
- Frozen means content unchanged
- Annotations are commentary, not content
- Enables review workflows on final documents
- Maintains signature validity

**Consequences**:
- Annotations may not be portable
- Need clear boundary between content and annotation
- Annotation integrity separate concern

---

## DD-013: Hash Chain Lineage with Merkle Trees

**Decision**: Documents form a hash chain via parent references, with block-level Merkle trees for granular proofs.

**Alternatives Considered**:
1. External version control only (Git, etc.)
2. Simple parent pointer without Merkle trees
3. Full blockchain with consensus mechanism
4. Centralized version registry

**Rationale**:
- Documents themselves become the chain — no external infrastructure required
- Content-addressable identity (hash = ID) makes forgery computationally infeasible
- Merkle trees enable block-level proofs without revealing entire document
- Supports selective disclosure and redaction proofs
- Compatible with external timestamping (RFC 3161, blockchain anchoring)
- Git has proven this model works at scale
- Decentralized verification — anyone with the documents can verify the chain

**Consequences**:
- Slightly larger documents (block index adds ~50-100 bytes per block)
- Hash algorithm becomes critical dependency (algorithm agility required)
- Chain verification requires access to ancestor documents (or trust in chain)
- Merkle proofs add complexity for implementers

**Key Insight**: The "blockchain-like" property comes from the hash chain structure, not from consensus mechanisms or distributed networks. The documents ARE the chain.

---

## DD-014: Timestamp Anchoring Options

**Decision**: Support multiple timestamp anchoring methods: RFC 3161 TSAs, blockchain anchoring, and aggregated timestamps.

**Alternatives Considered**:
1. RFC 3161 only (traditional)
2. Blockchain only (decentralized)
3. No timestamp support (signatures only)
4. Proprietary timestamp service

**Rationale**:
- RFC 3161 is established standard, widely supported
- Blockchain anchoring provides decentralized, censorship-resistant timestamps
- Aggregated timestamps (OpenTimestamps-style) provide efficiency for high-volume use
- Different use cases have different trust requirements
- Legal contexts may require specific timestamp authorities
- Academic/archival contexts may prefer decentralized proofs

**Consequences**:
- Multiple code paths for timestamp verification
- Trust model varies by timestamp type
- Blockchain timestamps have latency (Bitcoin: ~10 min, Ethereum: ~12 sec)
- RFC 3161 requires trust in TSA; blockchain requires trust in chain security

---

## DD-015: State-Aware Progressive Enhancement Presentation

**Decision**: Presentation precision evolves with document maturity — reactive presentation for drafts, with precise layout snapshots required for FROZEN and PUBLISHED states.

**Alternatives Considered**:
1. Always require precise layouts (PDF model)
2. Never require precise layouts (pure semantic)
3. Optional precise layouts regardless of state
4. External rendering only (no stored layouts)

**Rationale**:
- **Rendering fidelity** — When frozen, the precise layout is required for rendering fidelity, but the document ID covers semantic content only. For legal contexts requiring appearance attestation, use scoped signatures (see Security Extension).
- **Legal/academic needs** — Citations reference "page 7, line 23" with confidence
- **Lifecycle alignment** — Precision emerges naturally as documents mature
- **No capability loss** — Semantic content always present for accessibility/search
- **Stable cross-references** — Internal refs ("see page 7") guaranteed stable once frozen
- Draft documents are fluid; layout doesn't matter yet
- Review documents can preview approximate pagination
- Frozen/published documents become immutable records with exact appearance

**Presentation Types**:
| Type | Purpose | When Required |
|------|---------|---------------|
| Reactive (paginated, continuous, responsive) | Hints and styles for renderers | Optional always |
| Precise (layouts/) | Exact coordinates for pixel-perfect reproduction | Required for FROZEN/PUBLISHED |

**Precise Layout Features**:
- Exact element coordinates (x, y, width, height)
- Content hash for staleness detection
- Page continuation markers for multi-page blocks
- Optional line-level precision for legal documents
- Font metrics for exact text reproduction

**Consequences**:
- FROZEN/PUBLISHED validation must check for precise layout
- Layout content hash must match current content (staleness check)
- State transition to FROZEN may fail if no precise layout exists
- Layout generation is external tooling responsibility
- Increases document size for frozen documents (layout data)

**Key Insight**: Just as document content becomes immutable when frozen, so does its visual appearance. The precise layout is part of the immutable record, but the document ID covers semantic content only. Scoped signatures (DD-018) allow separate attestation of appearance when required.

---

## DD-016: Unified Anchor System

**Decision**: Define a single anchor addressing system (Content Anchor URIs and ContentAnchor objects) in the core specification, consumed by all extensions.

**Alternatives Considered**:
1. Per-extension addressing (each extension defines its own `blockRef` + `range`)
2. Only named anchors (no offset-based addressing)
3. XPath-style addressing
4. Character offsets only (no block-level anchors)

**Rationale**:
- **Consistency** — All extensions (collaboration, phantoms, presentation, semantic) use the same addressing model
- **Reduces duplication** — One schema definition, one validation rule set, one offset computation algorithm
- **Named anchors as stable alternative** — Offset-based anchors are fragile under edits; named anchor marks provide a stable alternative that moves with content
- **State-dependent validation** — Broken anchors are warnings in DRAFT/REVIEW (content is fluid) but errors in FROZEN/PUBLISHED (content is immutable)
- **Link mark integration** — Internal links use the same URI syntax (`#blockId`) as external links use URLs, keeping the mark model simple

**Consequences**:
- Block IDs are now SHOULD (upgraded from MAY) for all blocks
- Block IDs are MUST when any referencing extension is active
- Named anchor IDs share the namespace with block IDs (uniqueness constraint)
- Implementations need offset adjustment logic for mutable documents

---

## DD-017: Phantom Layer

**Decision**: Provide an off-page annotation layer (phantoms) that is outside the hashing boundary and mutable in all states.

**Alternatives Considered**:
1. Extend the collaboration extension with spatial annotations
2. Use the core annotation layer for all annotation types
3. Embed annotations inline in content blocks
4. No spatial annotation support

**Rationale**:
- **Orthogonal to inline annotations** — Phantoms are spatially organized clusters, not inline comments. They serve a different purpose (research notes, marginalia, mind-maps)
- **Outside hashing boundary** — Phantoms are commentary, not content. Adding a margin note should never change document identity or invalidate signatures
- **Mutable in all states** — Even frozen/published documents benefit from annotation. This follows the PDF model where annotations don't affect the document
- **Scope control** — Private, shared, and role-based visibility allows personal notes alongside team annotations
- **Fork behavior** — Shared phantoms travel with the document; private ones stay with their author

**Consequences**:
- New `phantoms/` directory in the archive
- Phantom block IDs are in a separate namespace from document content
- Applications must decide how to render clusters spatially (margin, sidebar, overlay)
- Fork operations must handle per-scope phantom copying

---

## DD-018: Scoped Signatures for Appearance Attestation

**Decision**: Add optional `scope` field to signatures, enabling per-signature attestation of content plus layout.

**Alternatives Considered**:
1. Include layout in the content hash (makes layout part of document identity)
2. Separate signature files for content vs. appearance
3. Always sign appearance (all signatures cover layout)
4. No appearance attestation (content-only signatures always)

**Rationale**:
- **Content identity vs. appearance attestation** — The document ID should represent semantic identity (what it says), not visual appearance (how it looks). But legal/notarial use cases need to attest that a specific rendering was certified
- **Backward compatible** — Existing signatures (no `scope`) continue to work unchanged as content-only attestation
- **Flexible** — Different signers can attest to different things. A notary signs content + letter layout; a reviewer signs content only
- **Extensible** — The `scope` object can be extended with additional fields (metadata, assets) without breaking existing signatures
- **JCS for determinism** — Using JCS serialization of the scope object provides deterministic bytes for signing

**Consequences**:
- Verification algorithm has two paths (legacy vs. scoped)
- Scoped signatures are larger (include scope object)
- Layout file hashes must be computed and included in scope
- Applications must expose the scope distinction in signature UI

---

## DD-019: Declarative Forms Validation Only

**Decision**: Form validation rules must be purely declarative JSON. No executable expressions (JavaScript or otherwise) are permitted.

**Alternatives Considered**:
1. JavaScript expression strings (like PDF form scripts)
2. Sandboxed expression language
3. WebAssembly-based validators
4. No custom validation (built-in validators only)

**Rationale**:
- **Consistent with DD-010** — The core specification explicitly excludes executable content. PDF JavaScript is cited as a cautionary tale in DD-010, and allowing it in form validation would undermine that decision
- **Security** — Expression evaluation opens injection attack vectors. Even "sandboxed" JavaScript has a long history of sandbox escapes
- **Declarative sufficiency** — The built-in validators (`required`, `minLength`, `maxLength`, `min`, `max`, `pattern`, `email`, `url`, `containsUppercase`, `containsDigit`, `containsSpecial`, `matchesField`) cover the vast majority of form validation needs
- **Pattern validator as escape hatch** — The `pattern` validator accepts regular expressions, providing complex string matching without executable code
- **Implementer simplicity** — Declarative rules can be validated by any JSON processor without requiring a JavaScript runtime

**Consequences**:
- Some highly dynamic validation (e.g., "field B required only if field A > 10") is not expressible. This is an acceptable limitation — such logic belongs in the application layer, not the document format
- The `pattern` validator inherits regex complexity concerns, but regex is well-understood and does not enable arbitrary code execution

---

## Open Questions

### OQ-001: Binary Variant

Should there be an optimized binary serialization (CBOR/MessagePack)?

**Status**: Deferred to v1.x
**Considerations**: Performance vs complexity tradeoff

### OQ-002: Streaming Support

How should very large documents support streaming/chunked access?

**Status**: Under investigation
**Considerations**: ZIP supports range requests; content chunking TBD

### OQ-003: Collaborative Editing Protocol

Should the spec define a sync protocol or just data structures?

**Status**: Extension territory
**Considerations**: Many existing protocols; don't reinvent

### OQ-004: Digital Rights Management

Should the format support DRM?

**Status**: Explicitly out of scope
**Considerations**: Opens governance issues; encryption provides confidentiality
